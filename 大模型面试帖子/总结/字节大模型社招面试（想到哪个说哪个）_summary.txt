使用模型: gemini-2.5-flash-lite
开始提问: 请总结这篇大模型面试经验分享的主要内容，提取关键面试经验、技巧和建议

一面面试回顾
1.概述技术背景，并重点介绍与大模型相关的项目经历。
	
2.详细解释 Transformer 的整体框架以及其中各个核心模块的作用。
	
3.Attention 计算公式中为何要除以 √dk？这一步骤的主要作用是什么？
	
4.在 Transformer 的训练过程中，梯度消失或梯度爆炸问题常见的原因是什么？
	
5.在监督微调（SFT）过程中您曾遇到哪些典型问题？请结合实际情况分享解决方法和经验。
	
6.在构建领域大模型时，应如何确定不同领域训练数据的比例？通常需考虑哪些关键因素？
	
7.为何当前主流的大语言模型普遍选择 Decoder-only 结构？与 Encoder-Decoder 架构相比，它具备哪些优势？
	
8.ADAM 优化器相比 SGD 做出了哪些重要改进？
	
9.请简要解释梯度下降的基本原理。
	
10.ADAM 是在 SGD 的哪些方面做了进一步优化？
	
11.给定一个不含重复元素的整数数组 nums，编写一个函数，返回该数组所有可能的子集（即其幂集）。
示例：
输入：nums = [1,2,3]
输出：[[],[1],[2],[3],[1,2],[1,3],[2,3],[1,2,3]]
	
二面
1.请简要介绍您的技术背景，并重点说明与大模型相关的项目经验及技术专长。
	
2.请详细阐述标准 Transformer Decoder 结构与 LLaMA 架构的主要差异。
	
3.对比三角函数位置编码与 RoPE（旋转位置编码）在数学实现上的不同。
	
4.分析这两种位置编码方式分别实现了哪些不同的功能特性。
	
5.请分步说明强化学习人类反馈（RLHF）的完整流程
	
6.请列举常见的大语言模型评估指标，例如：
困惑度（Perplexity）
准确率（Accuracy）
BLEU/ROUGE 等生成文本评价指标
人工评估指标
并简要说明模型评估的一般流程与方法。
	
7.请解释 LoRA（低秩适应）的基本原理。
	
8.分析 LoRA 能够加速模型训练的具体机制。
	
9.说明“秩”（Rank）的数学概念及其在 LoRA 中起到的作用。
	
10.请分类介绍 Reward Bench 中常见的奖励模型类型。
	
11.详细描述奖励模型的训练过程。
	
12.阐述奖励模型训练所使用的目标函数。
	
13.请写出 DPO（直接偏好优化）的损失函数公式。
	
14.说明 DPO 方法的训练目标。
	
15.分析 DPO 相比传统优化方法的主要改进之处。
	
16.给定一个长度为 n+1 的数组 nums，元素取值范围在 [1, n] 之间，其中有一个数值重复出现一次，请找出该重复数字。
	
#互联网大厂[话题]# #程序员[话题]# #职场[话题]# #面试日常[话题]# #大模型[话题]# #面经[话题]# #面试求职[话题]# #社招[话题]# #求职[话题]# #面试技巧[话题]#
当前使用模型: gemini-2.5-flash-lite
调用Gemini API时发生错误: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\nPlease retry in 25.988073656s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}
模型 gemini-2.5-flash-lite 配额已用完，尝试切换模型或API密钥...
已切换到新API密钥: AIzaSyATTa...
已切换到新模型: gemini-1.5-flash
调用Gemini API时发生错误: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}
处理失败